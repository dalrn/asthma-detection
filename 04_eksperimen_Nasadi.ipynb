{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339807a2",
   "metadata": {},
   "source": [
    "#  Asthma Detection with ResNet\n",
    "Notebook ini menjelaskan setiap langkah dalam pipeline deteksi asma menggunakan deep learning dengan fitur MFCC dari audio napas pasien.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a44994",
   "metadata": {},
   "source": [
    "## üîß 1. Import Library\n",
    "Mengimpor semua library yang dibutuhkan, termasuk `librosa` untuk membaca audio, `torch` untuk deep learning, dan `sklearn` untuk split data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe1a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2c657",
   "metadata": {},
   "source": [
    "## üìÅ 2. Load Dataset Audio\n",
    "Menentukan path ke folder yang berisi file `.wav` suara pernapasan penderita asma, kemudian memuat dan membagi menjadi data latih dan uji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8217bb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ditemukan 98 file audio di: C:\\Users\\Asus\\asthma-detection\\Dataset\\Fraiwan_dkk\\Audio\\Asthma\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Ganti dengan path lokal yang kamu miliki (gunakan raw string agar aman di Windows)\n",
    "base_path = Path(r\"C:/Users/Asus/asthma-detection/Dataset/Fraiwan_dkk/Audio/Asthma\")\n",
    "\n",
    "# Cek apakah path valid\n",
    "if not base_path.exists():\n",
    "    raise RuntimeError(\"‚ùå Path tidak ditemukan. Pastikan folder sudah benar!\")\n",
    "\n",
    "# Ambil semua file .wav\n",
    "file_paths = list(base_path.glob(\"*.wav\"))\n",
    "if not file_paths:\n",
    "    raise RuntimeError(\"‚ùå Tidak ada file .wav ditemukan dalam folder.\")\n",
    "\n",
    "print(f\"‚úÖ Ditemukan {len(file_paths)} file audio di: {base_path}\")\n",
    "\n",
    "# Dummy label semua asma (label = 1)\n",
    "labels = [1] * len(file_paths)\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "    file_paths, labels, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68cc73a",
   "metadata": {},
   "source": [
    "## üìä 3. Dataset Class: Ekstraksi MFCC\n",
    "Menggunakan `librosa.load` untuk membaca audio dan `torchaudio.transforms.MFCC` untuk mengekstrak fitur suara dalam bentuk MFCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48556817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "class AsthmaAudioDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = torchaudio.transforms.MFCC(n_mfcc=40)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Gunakan librosa agar lebih stabil di Windows\n",
    "        waveform, sample_rate = librosa.load(str(self.file_paths[idx]), sr=None)\n",
    "        waveform = torch.tensor(waveform).unsqueeze(0)\n",
    "        mfcc = self.transform(waveform).squeeze(0).unsqueeze(0)\n",
    "        return mfcc, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bf454",
   "metadata": {},
   "source": [
    "## üì¶ 4. Membuat DataLoader\n",
    "Membungkus dataset ke dalam `DataLoader` agar bisa diakses dalam mini-batch saat training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3735378",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        return F.relu(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a40919",
   "metadata": {},
   "source": [
    "## üß† 5. Arsitektur ResNet\n",
    "Menggunakan pretrained ResNet18 dari `torchvision.models`, diubah agar bisa menerima input 1 channel (MFCC) dan disesuaikan untuk klasifikasi binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ad2f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride):\n",
    "        strides = [stride] + [1]*(blocks-1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, s))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return self.fc(out)\n",
    "\n",
    "model = ResNet(ResBlock, [2, 2, 2], num_classes=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d850e0",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 6. Setup Training\n",
    "Menentukan device (CPU/GPU), loss function, dan optimizer untuk melatih model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7d288be",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1769131",
   "metadata": {},
   "source": [
    "## üèãÔ∏è 7. Training Loop\n",
    "Melatih model menggunakan data yang sudah dibagi dengan loss function dan optimizer yang sudah ditentukan. Setiap batch diproses dan dilakukan backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d6407b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AsthmaAudioDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = torchaudio.transforms.MFCC(n_mfcc=40)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load audio dengan librosa\n",
    "        waveform, sample_rate = librosa.load(str(self.file_paths[idx]), sr=16000)\n",
    "        waveform = torch.tensor(waveform).unsqueeze(0)  # [1, n]\n",
    "\n",
    "        # Hitung MFCC\n",
    "        mfcc = self.transform(waveform)  # [1, 40, time]\n",
    "\n",
    "        # Tetapkan panjang tetap\n",
    "        fixed_length = 400\n",
    "        if mfcc.shape[-1] < fixed_length:\n",
    "            pad_amt = fixed_length - mfcc.shape[-1]\n",
    "            mfcc = F.pad(mfcc, (0, pad_amt))  # padding di belakang\n",
    "        else:\n",
    "            mfcc = mfcc[..., :fixed_length]  # crop kalau kepanjangan\n",
    "\n",
    "        return mfcc, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bba715",
   "metadata": {},
   "source": [
    "## üß™ 8. Evaluasi Model\n",
    "Menggunakan data test untuk mengevaluasi akurasi model setelah training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42430ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python313\\Lib\\site-packages\\torchaudio\\functional\\functional.py:585: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Buat DataLoader setelah Dataset class sudah benar dan file sudah dibaca\n",
    "train_dataset = AsthmaAudioDataset(train_paths, train_labels)\n",
    "test_dataset = AsthmaAudioDataset(test_paths, test_labels)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f45fa9",
   "metadata": {},
   "source": [
    "## üíæ 9. Simpan Model\n",
    "Menyimpan model yang sudah dilatih ke file `.pt` agar bisa digunakan di lain waktu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a7a3778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 1 epoch selesai. Loss terakhir: 0.030389005318284035\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for mfccs, labels in train_loader:\n",
    "    mfccs = mfccs.to(device)\n",
    "    labels = labels.to(device, dtype=torch.long)\n",
    "    outputs = model(mfccs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"‚úÖ 1 epoch selesai. Loss terakhir:\", loss.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
